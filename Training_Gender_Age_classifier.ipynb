{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.cuda.empty_cache()\n",
    "import torchvision \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "import json \n",
    "import shutil \n",
    "import pandas as pd \n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import models\n",
    "from PIL import Image\n",
    "import os\n",
    "import src.dataset_ as dl\n",
    "import src.utility_ as utility\n",
    "import src.model_ as cnn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('./data/data_dict.json')\n",
    "data_dict = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of images',len(data_dict[0]))\n",
    "data_dict[0]['30601258@N03/landmark_aligned_face.1.10399646885_67c7d20df9_o.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the images\n",
    "images_list = list(data_dict[0].keys())\n",
    "\n",
    "# shows \n",
    "utility.show_img(images_list,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_Gender_Dataset = dl.Gender_Age_Classifier_dataset(json_file='./data/data_dict.json',root_dir='./data/aligned',\n",
    "transforms=transforms.Compose([transforms.ToTensor(),transforms.Resize((52,52))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [int(len(Age_Gender_Dataset)*0.8), len(Age_Gender_Dataset)-int(len(Age_Gender_Dataset)*0.8)]\n",
    "train_Dataset, val_Dataset = torch.utils.data.random_split(Age_Gender_Dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_Dataset,batch_size=2,shuffle=True)\n",
    "val_dataloader = DataLoader(val_Dataset,batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "# Getting gpu for training \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = \"Resnet_multi_task\"\n",
    "model = cnn_models.Resnet_multi_task().to(device)\n",
    "\n",
    "# sample_img = torch.randn(1,3,104,104).to(device)\n",
    "# model(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "gender_criterion = torch.nn.CrossEntropyLoss()\n",
    "age_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "# input parameters \n",
    "epochs = 5\n",
    "best_accuracy = torch.tensor(0.0)\n",
    "resume_weights = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
    "\t\"\"\"Save checkpoint if a new best is achieved\n",
    "\t\n",
    "\tstate: checkpoint we want to save \n",
    "\tis_best: if this checkpoint is the best so far\n",
    "\tcheckpoint_path: path to save checkpoint\n",
    "\tbest_model_path: path to save best model\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tf_path = checkpoint_path\n",
    "\n",
    "\t# save checkpoint data to the path given, checkpoint_path\n",
    "\ttorch.save(state, f_path)\n",
    "\n",
    "\t# if it is a best model, min validation loss\n",
    "\tif is_best:\n",
    "\n",
    "\t\tbest_fpath = best_model_path\n",
    "\t\t# copy that checkpoint file to best path given, best_model_path\n",
    "\n",
    "\t\tshutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "def accuracy_metric(pred,age,gender):\n",
    "\t\n",
    "\tsize = len(pred[0])\n",
    "\t# print(size)\n",
    "\t# print(age)\n",
    "\t# print(gender)\n",
    "\t# print(pred[0].argmax(1))\n",
    "\t# print(pred[1].argmax(1))\n",
    "\tcorrect_age = (pred[0].argmax(1) == age).type(torch.float).sum().item()\n",
    "\tcorrect_gender = (pred[1].argmax(1) == gender).type(torch.float).sum().item()\n",
    "\t# print(correct_age)\n",
    "\t# print(correct_age)\n",
    "\tage_acc = correct_age / size\n",
    "\tgender_acc = correct_gender / size\n",
    "\n",
    "\treturn age_acc,gender_acc\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,model,age_criterion,gender_criterion,optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    correct_age,correct_gender = 0,0\n",
    "\n",
    "    for batch,(img,age,gender) in enumerate(dataloader):\n",
    "        \n",
    "        \n",
    "        img, age, gender = img.to(device), age.to(device), gender.to(device)\n",
    "        \n",
    "        # compute prediction error \n",
    "        pred = model(img)\n",
    "\n",
    "        age_loss = age_criterion(pred[0],age.long())\n",
    "        gender_loss = gender_criterion(pred[1],gender.long())\n",
    "\n",
    "        loss = (age_loss + gender_loss)/ 2 \n",
    "\n",
    "        # Backprop \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct_age += (pred[0].argmax(1) == age).type(torch.float).sum().item()\n",
    "        correct_gender += (pred[1].argmax(1) == gender).type(torch.float).sum().item()        \n",
    "        \n",
    "        if batch % 1000 == 0:\n",
    "            age_loss,gender_loss,current = age_loss.item(),gender_loss.item(), batch*len(img)\n",
    "            print(f\"Age loss: {age_loss:>7f} Gender loss: {gender_loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    age_acc = correct_age / size\n",
    "    gender_acc = correct_gender / size\n",
    "\n",
    "    print(f\" Train Age accuracy:{age_acc:>2f} Train Gender accuracy:{gender_acc:>2f}\")\n",
    "            \n",
    "\n",
    "    \n",
    "def test(dataloader, model,valid_loss_min_input,optimizer,age_criterion,gender_criterion,epoch,checkpoint_path,best_model_path):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = valid_loss_min_input \n",
    "\n",
    "    test_age_loss,test_gender_loss, correct_age,correct_gender = 0,0,0,0\n",
    "\n",
    "    for batch,(img,age,gender) in enumerate(dataloader):\n",
    "\n",
    "        img,age,gender = img.to(device), age.to(device), gender.to(device)\n",
    "        pred = model(img)\n",
    "\n",
    "        test_age_loss += age_criterion(pred[0],age.long())\n",
    "        test_gender_loss += gender_criterion(pred[1],gender.long())\n",
    "\n",
    "        correct_age += (pred[0].argmax(1) == age).type(torch.float).sum().item()\n",
    "        correct_gender += (pred[1].argmax(1) == gender).type(torch.float).sum().item()\n",
    "        \n",
    "    test_age_loss/=num_batches\n",
    "    test_gender_loss /= num_batches\n",
    "    correct_age /= size\n",
    "    correct_gender /= size\n",
    "\n",
    "    print(f\"Test Error \\n Age Accuracy: {100*correct_age:>2f} Gender Accuracy: {100*correct_gender:>2f} \\n Age loss: {test_age_loss:>7f} Gender loss: {test_gender_loss:>7f}\")\n",
    "\n",
    "    combined_loss = (test_age_loss + test_gender_loss)/ 2 \n",
    "\n",
    "    # create checkpoint variable and add important data\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'valid_loss':combined_loss,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "    # save checkpoint   \n",
    "    save_checkpoint(checkpoint, False, checkpoint_path, best_model_path)\n",
    "        \n",
    "    if combined_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,combined_loss))\n",
    "        # save checkpoint as best model\n",
    "        save_checkpoint(checkpoint, True, checkpoint_path, best_model_path)\n",
    "        valid_loss_min = combined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "checkpoint_path = \"./models/checkpoint/{}_checkpoint.pt\".format(model_architecture)\n",
    "best_model_path = \"./models/best_model/{}_best_model.pt\".format(model_architecture)\n",
    "\n",
    "valid_loss_min_input = np.Inf\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f'Epoch:{i+1}\\n ------------------------------')\n",
    "    train(train_dataloader, model,age_criterion,gender_criterion,optimizer)\n",
    "    test(val_dataloader, model,valid_loss_min_input,optimizer,age_criterion,gender_criterion,i,checkpoint_path,best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a9c223cf103f8e4bd3016efd356f952fbd4651dca158957834db2968df2eff7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
