{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.cuda.empty_cache()\n",
    "import torchvision \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import json \n",
    "import shutil \n",
    "import pandas as pd \n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import models\n",
    "from PIL import Image\n",
    "import os\n",
    "import src.dataset as dl\n",
    "import src.utility as utility\n",
    "import src.model as cnn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted ranges- (0-2, 3-6, 8-13, 15-20, 25-32, 34-43, 45-53, 55-100)\n",
    "\n",
    "def valid_ext(ext):\n",
    "    return ext.lower() in ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "\n",
    "def inference(model, test_dir):\n",
    "\n",
    "        \"\"\"Inference for test \"\"\"\n",
    "\n",
    "        age_cats = {0:\"0-2\", 1:\"3-6\", 2:\"8-13\", 3:\"15-20\", 4:\"22-32\", 5:\"34-43\", 6:\"45-53\", 7:\"55-100\"}\n",
    "        gender_cats = {0:\"f\",1:\"m\",2:\"u\"}\n",
    "\n",
    "        output = {}\n",
    "\n",
    "        for root, dirs, files in os.walk(test_dir):\n",
    "            for file in files:\n",
    "                \n",
    "                path = os.path.join(root, file)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if not valid_ext(file[-4:]):\n",
    "                        print(path,'is not valid image. Expected extension: .jpg, .jpeg, .png')\n",
    "                        continue\n",
    "                    \n",
    "                    else:\n",
    "                        img = Image.open(path)\n",
    "                        img = img.convert('RGB')\n",
    "                        img = img.resize((104, 104))\n",
    "                        \n",
    "                        img = torch.tensor(np.array(img)).unsqueeze(0)\n",
    "                        img = img.permute(0, 3, 1, 2).float()\n",
    "\n",
    "                        age_logits, gender_logits = model(img.to(device))\n",
    "                        \n",
    "                        output[str(path)] = {'age':age_cats[age_logits.argmax(1).item()],\n",
    "                                            'gender':gender_cats[gender_logits.argmax(1).item()]}\n",
    "                        \n",
    "        return output                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Base_CNN_multi_task(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(10, 32, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3872, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (head1): Linear(in_features=100, out_features=8, bias=True)\n",
       "  (head2): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "base_cnn_model = cnn_models.Base_CNN_multi_task().to(device)\n",
    "\n",
    "# load model weights\n",
    "# base_cnn_model.load_state_dict(torch.load(\"models/base_cnn_multi_task_model.pt\"))\n",
    "\n",
    "# root = os.getcwd()\n",
    "\n",
    "# model parameters \n",
    "model_params = torch.load(\"./models/best_model/best_model.pt\")\n",
    "\n",
    "base_cnn_model.load_state_dict(model_params['state_dict'])\n",
    "base_cnn_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_dir = './data/test/'\n",
    "output = inference(base_cnn_model, inf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'./data/test/im1.jpg': {'age': '22-32', 'gender': 'f'}, './data/test/im2.jpg': {'age': '22-32', 'gender': 'f'}, './data/test/im3.jpg': {'age': '45-53', 'gender': 'f'}, './data/test/im4.jpg': {'age': '0-2', 'gender': 'm'}}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a9c223cf103f8e4bd3016efd356f952fbd4651dca158957834db2968df2eff7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
